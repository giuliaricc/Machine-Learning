if (!require("readr")) install.packages("readr")
if (!require("dplyr")) install.packages("dplyr")
if (!require("caret")) install.packages("caret")
if (!require("e1071")) install.packages("e1071")

library(readr)
library(dplyr)
library(caret)
library(e1071)

#tengo una copia dell'originale
train <- read_csv("/Users/gersiprendushi/Desktop/home-data-for-ml-course/train.csv")
prova <- read_csv("/Users/gersiprendushi/Desktop/home-data-for-ml-course/test.csv")

sample <- read_csv("/Users/gersiprendushi/Desktop/home-data-for-ml-course/sample_submission.csv")
#dataset che modificherò
test_data <- train

test_data <- test_data[,-1]

#Vediamo ogni riga quanti NaN ha
NaN_per_row <- rowSums(is.na(test_data))
test_data$na_count <- NaN_per_row #aggiungo una colonna che conta i NaN di ogni riga
max(test_data$na_count, na.rm = TRUE) #sembra che ogni osservazione abbia al massimo 10-15 NA (su 80)
# quindi non eliminiamo nessuna riga
# anche perchè alcuni Na non corrispondono a dati mancanti, ma sono collegati a risposte precedenti
test_data <- test_data %>% select(-na_count) #tolgo dal dataset la colonna che mi conta i NaN
rm(NaN_per_row)

#Ora vediamo quali colonne hanno troppi NaN:
NaN_per_column <- colSums(is.na(test_data))
threshold <- 0.40 * nrow(test_data) #ho messo la soglia del 40%
colonne_con_troppi_NaN <- names(NaN_per_column[NaN_per_column > threshold])
colonne_con_troppi_NaN
#quattro colonne hanno piu del 40% di NaN

#i NaN della colonna Alley significano che non vogliono l'alley, NON che manca il dato
test_data$Alley[is.na(test_data$Alley)] <- "UNWANTED" #sostituisco i NaN con "Non voluto"
#idem per fireplace quality
test_data$FireplaceQu[is.na(test_data$FireplaceQu)] <- "UNWANTED"

#controllare anche le altre tre dal file "descrizione"
test_data$PoolQC[is.na(test_data$PoolQC)] <- "PoolUnwanted"
test_data$Fence[is.na(test_data$Fence)] <- "FenceUnwanted"
test_data$MiscFeature[is.na(test_data$MiscFeature)] <- "FeaturesUnwanted"
test_data$BsmtQual[is.na(test_data$BsmtQual)] <- "BasementUnwanted"
test_data$BsmtCond[is.na(test_data$BsmtCond)] <- "BasementUnwanted"
test_data$BsmtExposure[is.na(test_data$BsmtExposure)] <- "BasementUnwanted"
test_data$BsmtFinType1[is.na(test_data$BsmtFinType1)] <- "BasementUnwanted"
test_data$BsmtFinType2[is.na(test_data$BsmtFinType2)] <- "BasementUnwanted"
test_data$GarageType[is.na(test_data$GarageType)] <- "GarageUnwanted"
test_data$GarageFinish[is.na(test_data$GarageFinish)] <- "GarageUnwanted"
test_data$GarageQual[is.na(test_data$GarageQual)] <- "GarageUnwanted"
test_data$GarageCond[is.na(test_data$GarageCond)] <- "GarageUnwanted"



# Lista delle variabili categoriche
# Converte le colonne character in factor
test_data[] <- lapply(test_data, function(x) if(is.character(x)) as.factor(x) else x)

# Ora trova le colonne di tipo factor
categorical_vars <- names(test_data)[sapply(test_data, is.factor)]

print(categorical_vars)

# Inizializza una lista per memorizzare i risultati
anova_results <- list()

# Ciclo for per eseguire ANOVA su ciascuna variabile categorica
# Crea un vettore per memorizzare le variabili categoriche significative
significant_categoricals <- c()

# Esegui ANOVA per tutte le variabili categoriche
for (var in categorical_vars) {
  # Esegui il test ANOVA
  anova_result <- aov(SalePrice ~ get(var), data = test_data)
  
  # Estrai il p-value
  p_value <- summary(anova_result)[[1]]$`Pr(>F)`[1]
  
  # Se il p-value è significativo (ad esempio < 0.05), aggiungi la variabile alla lista
  if (p_value < 0.05) {
    significant_categoricals <- c(significant_categoricals, var)
  } else {
    # Stampa le variabili non significative
    print(paste("Non significativa:", var, "con p-value:", p_value))
  }

}
# Ora "significant_categoricals" contiene le variabili significative
print(significant_categoricals)

# Crea una matrice di queste variabili per uso successivo (ad esempio, per One-Hot Encoding)
significant_categorical_data <- test_data[, significant_categoricals]

significant_categorical_data$ExterQual <- as.numeric(factor(significant_categorical_data$ExterQual, levels = c("Po", "Fa", "TA", "Gd", "Ex"), labels = c(1, 2, 3, 4, 5)))
significant_categorical_data$ExterCond <- as.numeric(factor(significant_categorical_data$ExterCond, levels = c("Po", "Fa", "TA", "Gd", "Ex"), labels = c(1, 2, 3, 4, 5)))
significant_categorical_data$BsmtQual <- as.numeric(factor(significant_categorical_data$BsmtQual, levels = c("BasementUnwanted", "Po", "Fa", "TA", "Gd", "Ex"), labels = c(0, 1, 2, 3, 4, 5)))
significant_categorical_data$BsmtCond <- as.numeric(factor(significant_categorical_data$BsmtCond, levels = c("BasementUnwanted", "Po", "Fa", "TA", "Gd", "Ex"), labels = c(0, 1, 2, 3, 4, 5)))
significant_categorical_data$HeatingQC <- as.numeric(factor(significant_categorical_data$HeatingQC, levels = c("Po", "Fa", "TA", "Gd", "Ex"), labels = c(1, 2, 3, 4, 5)))
significant_categorical_data$KitchenQual <- as.numeric(factor(significant_categorical_data$KitchenQual, levels = c("Po", "Fa", "TA", "Gd", "Ex"), labels = c(1, 2, 3, 4, 5)))
significant_categorical_data$FireplaceQu <- as.numeric(factor(significant_categorical_data$FireplaceQu, levels = c("FireplaceUnwanted", "Po", "Fa", "TA", "Gd", "Ex"), labels = c(0, 1, 2, 3, 4, 5)))
significant_categorical_data$GarageQual <- as.numeric(factor(significant_categorical_data$GarageQual, levels = c("GarageUnwanted", "Po", "Fa", "TA", "Gd", "Ex"), labels = c(0, 1, 2, 3, 4, 5)))
significant_categorical_data$GarageCond <- as.numeric(factor(significant_categorical_data$GarageCond, levels = c("GarageUnwanted", "Po", "Fa", "TA", "Gd", "Ex"), labels = c(0, 1, 2, 3, 4, 5)))
significant_categorical_data$PoolQC <- as.numeric(factor(significant_categorical_data$PoolQC, levels = c("PoolUnwanted", "Fa", "TA", "Gd", "Ex"), labels = c(0, 1, 2, 3, 4)))

#ora metto in dataset le categoriche che ho trasformato "a scala"
cat_to_num_data <- significant_categorical_data[, sapply(significant_categorical_data, is.numeric)]


#ora mi occupo delle variabili che sono numeriche 
numeric_data <- test_data[, sapply(test_data, is.numeric)]
head(numeric_data)

#estraggo le categoriche da significant
cat_one_hot <- significant_categorical_data %>% select(where(~ !is.numeric(.)))

# Creiamo il modello per One-Hot Encoding
library(caret)
dummies <- dummyVars("~ .", data = cat_one_hot)
# Applichiamo il modello di One-Hot Encoding per ottenere il dataframe con le variabili dummy
categorical_data_encoded <- as.data.frame(predict(dummies, newdata = cat_one_hot))

#test_data: dataset iniziale
#numeric_data : dataset delle SOLE variabili che erano numeriche fin dall'inizio
#cat_to_num_data : dataset delle variabili che ho "reso numeriche" a scala (ex: bad=0,good=1, excellent=2)
#categorical_data_encoded : dataset delle variabili che ho reso numeriche con l'one hot encoding

# ora plottiamo la matrice delle sole variabili numeriche "naturali"

#ora vediamo quali variabili sono collegate col target (utili) e quali no
cor_target <- cor(numeric_data, use = "complete.obs")["SalePrice", ]
cor_target_sorted <- sort(cor_target, decreasing = TRUE)
print(cor_target_sorted)
threshold <- 0.2  # Soglia di correlazione minima
selected_vars <- names(cor_target_sorted[abs(cor_target_sorted) >= threshold])
low_corr_vars <- names(cor_target[abs(cor_target) < 0.2])
numeric_data <- numeric_data[, selected_vars]
cat("Numero di variabili con bassa correlazione con SalePrice:", length(low_corr_vars), "\n")
print(low_corr_vars)  # Stampa i nomi delle variabili con bassa correlazione


library(ggplot2)
cor_target <- data.frame(Variable = names(cor_target_sorted), Correlation = cor_target_sorted)
ggplot(cor_target, aes(x = reorder(Variable, Correlation), y = Correlation, fill = Correlation)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  theme_minimal() +
  labs(title = "Correlation between variables and target")

#costruiamo la matrice di correlazione
cor_matrix <- cor(numeric_data[, -which(names(numeric_data) == "SalePrice")], use = "complete.obs")
if (!require("ggcorrplot")) {
  install.packages("ggcorrplot")
}

library(ggcorrplot)
ggcorrplot(cor_matrix, hc.order = TRUE, type = "lower", lab = TRUE)

library(caret)  # Assicurati che il pacchetto sia installato
high_corr <- findCorrelation(cor_matrix, cutoff = 0.9)  # Identifica le colonne da rimuovere
if(length(high_corr)<0){
  numeric_data <- numeric_data[, -high_corr]  # Rimuove le variabili con alta correlazione (>0.9)
}

# È la matrice di correlazione tra le variabili numeriche del dataset
# type = "lower": Mostra solo la parte inferiore della matrice di correlazione (dato che la matrice è simmetrica, evita di ripetere le informazioni)
# Identificare e rimuovere le variabili altamente correlate

# Controlliamo quante variabili sono state rimosse
length(high_corr)  # Mostra quante variabili sono state eliminate

library(car)  # Assicurati che il pacchetto sia installato
# Calcolo del Variance Inflation Factor (VIF) per le variabili numeriche
vif_values <- vif(lm(SalePrice ~ ., data = numeric_data))
# Stampa dei valori VIF
print(vif_values)
#Variabili con VIF elevato: GrLivArea: VIF = 114.60, TotRmsAbvGrd: VIF = 65.16
#Questi due valori di VIF sono molto alti quindi li rimuovo dal dataset per ridurre la multicollinearità
# Identifica le variabili con VIF >= 10
high_vif_vars <- names(vif_values[vif_values >= 10])
# Rimuovi le variabili con VIF >= 10
numeric_data <- numeric_data[, !names(numeric_data) %in% high_vif_vars]
# Ricalcola il VIF dopo la rimozione
vif_values <- vif(lm(SalePrice ~ ., data = numeric_data))
print(vif_values)
#ora tutti i vif sono inferiori a 10

#ora unisco i 3 dataset
complete_clean <- cbind(numeric_data,cat_one_hot,categorical_data_encoded)

summary(complete_clean)
y <- train$SalePrice

complete_clean <- complete_clean[,-1]

model <- lm(y ~ ., data = complete_clean)  # Regressione con tutte le variabili indipendenti

summary(model)


##ora rifaccio tutto per il test
# Modifiche da fare anche al dataset di test (prova)
prova <- prova[,-1]  # Come nel caso di test_data, elimina la prima colonna se necessario

# Analisi NaN per il dataset di test (prova)
NaN_per_row_prova <- rowSums(is.na(prova))
prova$na_count <- NaN_per_row_prova
max(prova$na_count, na.rm = TRUE)

# Rimuovi le righe che contengono NaN (se necessario) e rimuovi la colonna na_count
prova <- prova %>% select(-na_count)

# Tratta le variabili categoriche nello stesso modo
prova$Alley[is.na(prova$Alley)] <- "UNWANTED"
prova$FireplaceQu[is.na(prova$FireplaceQu)] <- "UNWANTED"
prova$PoolQC[is.na(prova$PoolQC)] <- "PoolUnwanted"
prova$Fence[is.na(prova$Fence)] <- "FenceUnwanted"
prova$MiscFeature[is.na(prova$MiscFeature)] <- "FeaturesUnwanted"
prova$BsmtQual[is.na(prova$BsmtQual)] <- "BasementUnwanted"
prova$BsmtCond[is.na(prova$BsmtCond)] <- "BasementUnwanted"
prova$BsmtExposure[is.na(prova$BsmtExposure)] <- "BasementUnwanted"
prova$BsmtFinType1[is.na(prova$BsmtFinType1)] <- "BasementUnwanted"
prova$BsmtFinType2[is.na(prova$BsmtFinType2)] <- "BasementUnwanted"
prova$GarageType[is.na(prova$GarageType)] <- "GarageUnwanted"
prova$GarageFinish[is.na(prova$GarageFinish)] <- "GarageUnwanted"
prova$GarageQual[is.na(prova$GarageQual)] <- "GarageUnwanted"
prova$GarageCond[is.na(prova$GarageCond)] <- "GarageUnwanted"

# Converte anche le variabili categoriche in factor nel dataset di test
prova[] <- lapply(prova, function(x) if(is.character(x)) as.factor(x) else x)

# Applica le stesse trasformazioni a scala per le variabili categoriche significative nel dataset di test
prova$ExterQual <- as.numeric(factor(prova$ExterQual, levels = c("Po", "Fa", "TA", "Gd", "Ex"), labels = c(1, 2, 3, 4, 5)))
prova$ExterCond <- as.numeric(factor(prova$ExterCond, levels = c("Po", "Fa", "TA", "Gd", "Ex"), labels = c(1, 2, 3, 4, 5)))
# Fai lo stesso per le altre variabili categoriche trasformate in numeriche

# Applica One-Hot Encoding alle variabili categoriche nel dataset di test
cat_one_hot_prova <- prova %>% select(where(~ !is.numeric(.)))
categorical_data_encoded_prova <- as.data.frame(predict(dummies, newdata = cat_one_hot_prova))

#dataset numerico
numeric_data_prova <- prova[, sapply(prova, is.numeric)]

# Ora unisci il dataset numerico e quello categorico
complete_clean_prova <- cbind(numeric_data_prova, categorical_data_encoded_prova)


# Identifica le variabili che sono state selezionate nel training
train_vars <- colnames(complete_clean)

# Assicurati che il dataset di test abbia tutte le variabili necessarie
# Aggiungi le colonne mancanti nel dataset di test come NA (se non sono presenti)
missing_cols <- setdiff(train_vars, colnames(complete_clean_prova))
for (col in missing_cols) {
  prova[[col]] <- NA
}

# Riordina le colonne nel dataset di test per corrispondere all'ordine di quelle nel dataset di addestramento
prova <- prova[, train_vars]

# Ora, puoi fare la previsione senza errori
y_pred <- predict(model, newdata = prova)

predictions <- predict(lm_model, newdata = numeric_test)

